{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09db11e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b72f9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from transformers import AutoTokenizer\n",
    "import asyncio\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "\n",
    "class MathDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str = \"AI-MO/aimo-validation-aime\",\n",
    "        model_name: str = \"openai:gpt-5-mini\",\n",
    "        tokenizer_name: str = \"Qwen/Qwen3-0.6B\",\n",
    "    ) -> None:\n",
    "        ds = load_dataset(data_path, split=\"train\")\n",
    "        self.questions = [str(question) for question in ds[\"problem\"]]\n",
    "        self.answers = [str(answer) for answer in ds[\"answer\"]]\n",
    "        self.agent = Agent(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    @property\n",
    "    def num_unique_tokens(self) -> int:\n",
    "        input_ids = self.tokenizer(self.questions)[\"input_ids\"]\n",
    "        return len(set(chain(*input_ids)))\n",
    "\n",
    "    @property\n",
    "    def token_counts(self) -> dict[str, int]:\n",
    "        input_ids = self.tokenizer(self.questions)[\"input_ids\"]\n",
    "        return {self.tokenizer.decode(i): c for i, c in Counter(chain(*input_ids)).items()}\n",
    "\n",
    "    def replace(self, old: str, new: str) -> None:\n",
    "        self.questions = [question.replace(old, new) for question in self.questions]\n",
    "\n",
    "    async def llm_transform(self, transform_instruction: str) -> None:\n",
    "        prompts = [\n",
    "            (\n",
    "                \"Transform the question according to the instruction.\\n\\n\"\n",
    "                \"**The transformed question must preserve the exact mathematical formulation \"\n",
    "                \"and all constraints of the original question. Do not alter numbers, variables, \"\n",
    "                \"equations, or assumptions.**\\n\\n\"\n",
    "                f\"# Question\\n\\n{question}\\n\\n\"\n",
    "                f\"# Instruction\\n\\n{transform_instruction}\\n\\n\"\n",
    "                \"Respond with the transformed question only.\"\n",
    "            )\n",
    "            for question in self.questions\n",
    "        ]\n",
    "\n",
    "        futures = [self.agent.run(prompt) for prompt in prompts]\n",
    "        results = await asyncio.gather(*futures)\n",
    "        self.questions = [result.output for result in results]\n",
    "\n",
    "\n",
    "dataevolve_agent = Agent(\n",
    "    \"openai:gpt-5-mini\",\n",
    "    deps_type=MathDataset,\n",
    "    instructions=(\n",
    "        \"You must optimize math questions to minimize the number if unique tokens while strictly preserving their \"\n",
    "        \"mathematical content. Your goal is to reduce the vocab size to under 512 unique tokens. You must ensure \"\n",
    "        \"the mathematical of all questions is unchanged, and that they still have the same answer.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_questions(ctx: RunContext[MathDataset]) -> str:\n",
    "    \"\"\"\n",
    "    Return the current list of questions as a stringified Python list.\n",
    "\n",
    "    What it does:\n",
    "      - Serializes the in-memory dataset questions to a string (e.g., for inspection/logging).\n",
    "\n",
    "    Returns:\n",
    "      str: A JSON-like string representation of the questions list.\n",
    "\n",
    "    Example:\n",
    "      >>> questions = get_questions(ctx)\n",
    "      >>> print(questions[:200])  # peek\n",
    "    \"\"\"\n",
    "    return str(ctx.deps.questions)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_num_unique_tokens(ctx: RunContext[MathDataset]) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of unique tokenizer tokens across all questions.\n",
    "\n",
    "    What it does:\n",
    "      - Tokenizes every question with the dataset tokenizer.\n",
    "      - Flattens token ids and counts unique ids to measure vocabulary breadth.\n",
    "\n",
    "    Returns:\n",
    "      int: Count of unique tokens in the current questions.\n",
    "\n",
    "    Use when:\n",
    "      - You want a single-number metric to track progress toward brevity.\n",
    "\n",
    "    Example:\n",
    "      >>> before = get_num_unique_tokens(ctx)\n",
    "      >>> replace(ctx, \"which is equal to\", \"=\")\n",
    "      >>> after = get_num_unique_tokens(ctx)\n",
    "      >>> print(before, after)\n",
    "    \"\"\"\n",
    "    return ctx.deps.num_unique_tokens\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_token_counts(ctx: RunContext[MathDataset]) -> str:\n",
    "    \"\"\"\n",
    "    Return a frequency table of decoded tokens across all questions (as pretty-printed JSON).\n",
    "\n",
    "    What it does:\n",
    "      - Tokenizes all questions.\n",
    "      - Aggregates counts per token id.\n",
    "      - Decodes each token id to text for human-readable analysis.\n",
    "\n",
    "    Returns:\n",
    "      str: JSON string mapping token (text) → frequency, sorted by token text.\n",
    "\n",
    "    Caveats:\n",
    "      - Decoding single-token pieces may show special tokens or partial subwords.\n",
    "\n",
    "    Example:\n",
    "      >>> counts_json = get_token_counts(ctx)\n",
    "      >>> print(counts_json[:500])\n",
    "    \"\"\"\n",
    "    return json.dumps(ctx.deps.token_counts, indent=2, sort_keys=True)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def replace(ctx: RunContext[MathDataset], old: str, new: str) -> None:\n",
    "    \"\"\"\n",
    "    Perform a literal string replacement across all questions.\n",
    "\n",
    "    What it does:\n",
    "      - Replaces every occurrence of `old` with `new` in each question.\n",
    "\n",
    "    Args:\n",
    "      old (str): Substring to be replaced (literal match).\n",
    "      new (str): Replacement text.\n",
    "\n",
    "    Side effects:\n",
    "      - Mutates the in-memory questions list.\n",
    "\n",
    "    Use when:\n",
    "      - Applying safe, pattern-free micro-edits (e.g., 'which equals' → '=').\n",
    "\n",
    "    Example:\n",
    "      >>> replace(ctx, \"is equal to\", \"=\")\n",
    "    \"\"\"\n",
    "    ctx.deps.replace(old, new)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "async def llm_transform(ctx: RunContext[MathDataset], transform_instruction: str) -> None:\n",
    "    \"\"\"\n",
    "    Apply an LLM-guided transformation to every question, under strict fidelity constraints.\n",
    "\n",
    "    What it does:\n",
    "      - For each question, prompts the LLM to transform text while preserving the exact\n",
    "        mathematical formulation (numbers, variables, relations, and constraints).\n",
    "      - Updates the questions list with the transformed outputs.\n",
    "\n",
    "    Args:\n",
    "      transform_instruction (str): A concise directive, e.g.,\n",
    "        - \"Shorten wording; replace phrases with symbols where safe.\"\n",
    "        - \"Remove filler; keep all constraints; keep LaTeX intact.\"\n",
    "\n",
    "    Side effects:\n",
    "      - Mutates the in-memory questions list with LLM outputs.\n",
    "\n",
    "    Example:\n",
    "      >>> await llm_transform(ctx, \"Shorten phrasing; prefer symbols; preserve all math.\")\n",
    "    \"\"\"\n",
    "    await ctx.deps.llm_transform(transform_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_ds = MathDataset()\n",
    "print(dataevolve_agent.run_sync(deps=math_ds).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81ee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1167"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_ds.num_unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd09b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aime-slm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
