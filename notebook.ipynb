{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09db11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72f9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class MathDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        questions: list[str],\n",
    "        answers: list[str],\n",
    "        model_name: str = \"openai:gpt-5\",\n",
    "        tokenizer_name: str = \"Qwen/Qwen3-0.6B\",\n",
    "    ) -> None:\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.agent = Agent(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    @property\n",
    "    def num_unique_tokens(self) -> int:\n",
    "        input_ids = self.tokenizer(self.questions)[\"input_ids\"]\n",
    "        n = len(set(chain(*input_ids)))\n",
    "        print(f\"There are {n} unique tokens.\")\n",
    "        return n\n",
    "\n",
    "    @property\n",
    "    def token_counts(self) -> dict[str, int]:\n",
    "        input_ids = self.tokenizer(self.questions)[\"input_ids\"]\n",
    "        return {self.tokenizer.decode(i): c for i, c in Counter(chain(*input_ids)).items()}\n",
    "\n",
    "    def replace(self, old: str, new: str) -> None:\n",
    "        self.questions = [question.replace(old, new) for question in self.questions]\n",
    "\n",
    "    async def llm_transform(self, transform_instruction: str) -> None:\n",
    "        prompts = [\n",
    "            (\n",
    "                \"Transform the question according to the instruction.\\n\\n\"\n",
    "                \"**The transformed question must preserve the exact mathematical formulation \"\n",
    "                \"and all constraints of the original question. Do not alter numbers, variables, \"\n",
    "                \"equations, or assumptions.**\\n\\n\"\n",
    "                f\"# Question\\n\\n{question}\\n\\n\"\n",
    "                f\"# Instruction\\n\\n{transform_instruction}\\n\\n\"\n",
    "                \"Respond with the transformed question only.\"\n",
    "            )\n",
    "            for question in self.questions\n",
    "        ]\n",
    "\n",
    "        futures = [self.agent.run(prompt) for prompt in prompts]\n",
    "        results = await asyncio.gather(*futures)\n",
    "        self.questions = [result.output for result in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f21d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = (\n",
    "    \"Quadratic polynomials $P(x)$ and $Q(x)$ have leading coefficients $2$ and $-2,$ respectively. \"\n",
    "    \"The graphs of both polynomials pass through the two points $(16,54)$ and $(20,53).$ Find $P(0) + Q(0).$\"\n",
    ")\n",
    "\n",
    "after = \"P(x) = 2x^2 + bx + c\\nQ(x) = -2x^2 + bx + c\\nP(16) = Q(16) = 54\\nP(20) = Q(20) = 53\\nfind P(0) + Q(0)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fc9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataevolve_agent = Agent(\"openai:gpt-5-mini\", deps_type=MathDataset)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_questions(ctx: RunContext[MathDataset]) -> str:\n",
    "    \"\"\"Return the current list of questions.\"\"\"\n",
    "    return str(ctx.deps.questions)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_num_unique_tokens(ctx: RunContext[MathDataset]) -> str:\n",
    "    \"\"\"Compute the number of unique tokenizer tokens across all questions.\"\"\"\n",
    "    return f\"There are {ctx.deps.num_unique_tokens} unique tokens.\"\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def get_token_counts(ctx: RunContext[MathDataset]) -> str:\n",
    "    \"\"\"Return a frequency table of decoded tokens across all questions as JSON.\"\"\"\n",
    "    return json.dumps(ctx.deps.token_counts, indent=2, sort_keys=True)\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "def replace(ctx: RunContext[MathDataset], old: str, new: str) -> str:\n",
    "    \"\"\"Perform a literal string replacement across all questions.\"\"\"\n",
    "    ctx.deps.replace(old, new)\n",
    "    return f\"There are {ctx.deps.num_unique_tokens} unique tokens after replacement.\"\n",
    "\n",
    "\n",
    "@dataevolve_agent.tool\n",
    "async def llm_transform(ctx: RunContext[MathDataset], transform_instruction: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply an LLM-guided transformation to every question, under strict fidelity constraints.\n",
    "\n",
    "    What it does:\n",
    "      - For each question, prompts the LLM to transform text while preserving the exact\n",
    "        mathematical formulation (numbers, variables, relations, and constraints).\n",
    "      - Updates the questions list with the transformed outputs.\n",
    "\n",
    "    Args:\n",
    "      transform_instruction (str): A concise directive, e.g.,\n",
    "        - \"Shorten wording; replace phrases with symbols where safe.\"\n",
    "        - \"Remove filler; keep all constraints; keep LaTeX intact.\"\n",
    "\n",
    "    Side effects:\n",
    "      - Mutates the in-memory questions list with LLM outputs.\n",
    "    \"\"\"\n",
    "    await ctx.deps.llm_transform(transform_instruction)\n",
    "    return f\"There are {ctx.deps.num_unique_tokens} unique tokens after transformation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5079786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1149 unique tokens.\n",
      "There are 797 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1149, 797)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/v1.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "ds_orig = MathDataset(questions=[item[\"question\"] for item in data], answers=[item[\"answer\"] for item in data])\n",
    "ds_v1 = MathDataset(questions=[item[\"transformed_question\"] for item in data], answers=[item[\"answer\"] for item in data])\n",
    "\n",
    "ds_orig.num_unique_tokens, ds_v1.num_unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7c174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d87536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\\\n",
    "# Reformat the math questions to use as few unique tokens as possible. Your goal is to minimize the vocab size.\n",
    "# You can check the current vocab size using the `get_num_unique_tokens` tool. You can modify the questions using\n",
    "# the `replace` and `llm_transform` tools. Your goal is to get the questions to contain under 512 unique tokens.\n",
    "\n",
    "# STRICT FIDELITY REQUIREMENTS\n",
    "# - Do NOT change numbers, variables, relations, equations, or assumptions.\n",
    "# - Keep math semantics intact.\n",
    "# - Output ONLY the DSL lines. No commentary, no markdown fences, no bullets.\n",
    "\n",
    "# DSL STYLE\n",
    "# - One fact/constraint per line.\n",
    "# - Prefer short tokens/symbols to reduce vocabulary.\n",
    "# - Allowed tokens (aim to stay within): shape, point, line, circle, angle, len, area, perimeter, radius, diameter, tangent, secant, intersects, parallel, equals, <, >, <=, >=, congruent, similar, midpoint, slope, product, sum, difference, ratio, gcd, lcm, prime, composite, integer, real, find.\n",
    "# - Use concise math forms: e.g., P(x)=2x^2+b*x+c, P(16)=54, area(ABCD)=m*sqrt(n).\n",
    "# - End with a single goal line starting with: \"find ...\"\n",
    "# \"\"\"\n",
    "\n",
    "# dataevolve_agent.run_sync(user_prompt=prompt, deps=ds_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aime-slm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
